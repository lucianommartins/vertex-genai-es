{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ur8xi4C7S06n"
   },
   "outputs": [],
   "source": [
    "# Copyright 2023 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAPoU8Sm5E6e"
   },
   "source": [
    "# Sumarização de textos com Generative AI na Vertex AI\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/language/intro_palm_api.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> Execute no Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/language/intro_palm_api.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      Veja no GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/blob/main/language/intro_palm_api.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "      Execute no Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvgnzT1CKxrO"
   },
   "source": [
    "## Visão geral\n",
    "A sumarização de textos produz um resumo conciso de um texto. Existem dois tipos principais de resumo de texto: extrativo e abstrativo. A sumarização extrativa envolve selecionar frases críticas do texto original e combiná-las para formar um resumo. A sumarização abstrativa envolve a geração de novas sentenças que representam os pontos principais do texto original. Neste notebook, você passará por alguns exemplos de como LLM podem ajudar na geração de sumários de textos.\n",
    "\n",
    "Saiba mais sobre resumo de texto na [documentação oficial](https://cloud.google.com/vertex-ai/docs/generative-ai/text/summarization-prompts)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d975e698c9a4"
   },
   "source": [
    "### Objetivo\n",
    "\n",
    "Neste tutorial, você aprenderá como usar LLM para sumarizar informações de texto trabalhando com os seguintes exemplos:\n",
    "- Sumário da transcrição\n",
    "- Sumarização de texto em bullets\n",
    "- Sumário de diálogo com tarefas realizadas\n",
    "- Tokenização de hashtag\n",
    "- Geração de títulos e cabeçalhos\n",
    "\n",
    "Você também aprenderá como avaliar resumos gerados por modelos comparando-os com resumos criados por humanos usando o `ROUGE` como uma estrutura de avaliação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f6d865e68adb"
   },
   "source": [
    "### Custos\n",
    "Este tutorial usa os seguintes componentes de Google Cloud:\n",
    "\n",
    "* Vertex AI Generative AI Studio\n",
    "\n",
    "Saiba mais sobre possíveis custos envolvidos [preços da Vertex AI](https://cloud.google.com/vertex-ai/pricing),\n",
    "e use a [Calculadora de preços](https://cloud.google.com/products/calculator/)\n",
    "para gerar uma estimativa de custo com base no uso projetado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bs9TZo0GJKCR"
   },
   "source": [
    "## Primeiros Passos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2a5AEr0lkLKD"
   },
   "source": [
    "### Instalando os SDK da Vertex AI e da Cloud Translate API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "148dd6321946",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install google-cloud-aiplatform google-cloud-translate --upgrade --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FLVWFKFwkLKE"
   },
   "source": [
    "**Somente Colab:** Descomente a célula a seguir para reiniciar o kernel ou use o botão para reiniciar o kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Hsqwn4hkLKE"
   },
   "outputs": [],
   "source": [
    "# # Reinicia automaticamente o kernel após as instalações para que seu ambiente possa acessar os novos pacotes\n",
    "# import IPython\n",
    "\n",
    "# app = IPython.Application.instance()\n",
    "# app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xe7OuYuGkLKF"
   },
   "source": [
    "### Autenticando seu ambiente de notebook\n",
    "* Se você estiver usando o **Colab** para executar este notebook, descomente a célula abaixo e continue.\n",
    "* Se você estiver usando o **Vertex AI Workbench**, confira as instruções de configuração [aqui](../setup-env/README.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U9Gx2SAZkLKF"
   },
   "outputs": [],
   "source": [
    "# from google.colab import auth\n",
    "# auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "960505627ddf"
   },
   "source": [
    "### Importando as bibliotecas necessárias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Somente Colab:** Descomente a célula a seguir para realizar o processo adequado de inicialização da SDK da Vertex AI.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import vertexai\n",
    "\n",
    "# PROJECT_ID = \"[seu-project-id]\"  # @param {type:\"string\"}\n",
    "# vertexai.init(project=PROJECT_ID, location=\"us-central1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PyQmSRbKA8r-"
   },
   "outputs": [],
   "source": [
    "from vertexai.preview.language_models import TextGenerationModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UP76a2la7O-a"
   },
   "source": [
    "#### Carregando o modelo `text-bison`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7isig7e07O-a"
   },
   "outputs": [],
   "source": [
    "generation_model = TextGenerationModel.from_pretrained(\"text-bison@001\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Criando a função *wrapper* para utilizar os modelos em Português\n",
    "\n",
    "Até o momento desde treinamento, as API do Generative AI Studio suportam somente interações no idioma inglês. Para fazermos interações utilizando o idioma português, vamos utilizar a [Cloud Translation API](https://cloud.google.com/translate) para traduzir as nossas solicitações do português para o inglês e as respostas da API de inglês para português."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import translate\n",
    "\n",
    "project_id = !gcloud config list project\n",
    "project_id = project_id[1].split('=')[1].strip()\n",
    "parent = f'projects/' + project_id\n",
    "\n",
    "\n",
    "def traduza(texto, idioma_destino):\n",
    "    client = translate.TranslationServiceClient()\n",
    "\n",
    "    response = client.translate_text(\n",
    "        parent=parent,\n",
    "        contents=[texto],\n",
    "        target_language_code=idioma_destino,\n",
    "        mime_type=\"text/plain\"\n",
    "    )\n",
    "\n",
    "    return response.translations[0].translated_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mu1UAhoTKn51"
   },
   "source": [
    "## Sumarização de texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TgZvJeBpJKCS"
   },
   "source": [
    "### Sumarizar uma transcrição\n",
    "\n",
    "Neste primeiro exemplo, você resume um texto sobre computação quântica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UA2NjngeJKCS"
   },
   "outputs": [],
   "source": [
    "prompt = traduza(\"\"\"\n",
    "Proporcione un resumen muy breve, no más de tres oraciones, para el siguiente artículo:\n",
    "\n",
    "Nuestras computadoras cuánticas funcionan manipulando qubits de una manera orquestada que llamamos algoritmos cuánticos.\n",
    "El desafío es que los qubits son tan sensibles que incluso la luz dispersa puede causar errores de cálculo, y el problema empeora a medida que crecen las computadoras cuánticas.\n",
    "Esto tiene consecuencias significativas, ya que los mejores algoritmos cuánticos que conocemos para ejecutar aplicaciones útiles requieren que las tasas de error de nuestros qubits sean mucho más bajas que las que tenemos hoy.\n",
    "Para llenar este vacío, necesitaremos la corrección del error cuántico.\n",
    "La corrección de errores cuánticos protege la información al codificarla en múltiples qubits físicos para formar un \"qubit lógico\" y se cree que es la única forma de producir una computadora cuántica a gran escala con tasas de error lo suficientemente bajas como para realizar cálculos útiles.\n",
    "En lugar de calcular en los qubits individuales, calcularemos en qubits lógicos. Al codificar un mayor número de qubits físicos en nuestro procesador cuántico en un qubit lógico, esperamos reducir las tasas de error para permitir algoritmos cuánticos útiles.\n",
    "\n",
    "Resumen:\n",
    "\n",
    "\"\"\", \"en\")\n",
    "\n",
    "print(\n",
    "    traduza(generation_model.predict(prompt, temperature=0.2, max_output_tokens=1024, top_k=40, top_p=0.8).text, \"es\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aade04b2e86a"
   },
   "source": [
    "Em vez de um resumo, podemos pedir um TL;DR (*\"too long; didn't read\"* ou \"muito longo; não li\" em tradução livre). Você pode comparar as diferenças entre as saídas geradas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0c0c0f3dfe10"
   },
   "outputs": [],
   "source": [
    "prompt = traduza(\"\"\"\n",
    "Proporcione un TL;DR para el siguiente artículo:\n",
    "\n",
    "Nuestras computadoras cuánticas funcionan manipulando qubits de una manera orquestada que llamamos algoritmos cuánticos.\n",
    "El desafío es que los qubits son tan sensibles que incluso la luz dispersa puede causar errores de cálculo, y el problema empeora a medida que crecen las computadoras cuánticas.\n",
    "Esto tiene consecuencias significativas, ya que los mejores algoritmos cuánticos que conocemos para ejecutar aplicaciones útiles requieren que las tasas de error de nuestros qubits sean mucho más bajas que las que tenemos hoy.\n",
    "Para llenar este vacío, necesitaremos la corrección del error cuántico.\n",
    "La corrección de errores cuánticos protege la información al codificarla en múltiples qubits físicos para formar un \"qubit lógico\" y se cree que es la única forma de producir una computadora cuántica a gran escala con tasas de error lo suficientemente bajas como para realizar cálculos útiles.\n",
    "En lugar de calcular en los qubits individuales, calcularemos en qubits lógicos. Al codificar un mayor número de qubits físicos en nuestro procesador cuántico en un qubit lógico, esperamos reducir las tasas de error para permitir algoritmos cuánticos útiles.\n",
    "\n",
    "TL;DR:\n",
    "\"\"\", \"en\")\n",
    "\n",
    "print(\n",
    "    traduza(generation_model.predict(prompt, temperature=0.2, max_output_tokens=1024, top_k=40, top_p=0.8).text, \"es\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5PATmHivJKCS"
   },
   "source": [
    "### Sumarizar em bullets\n",
    "No exemplo a seguir, você usa o mesmo texto sobre computação quântica, mas pede ao modelo para sumarizar com bullets. Sinta-se à vontade para alterar o prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2orkDF2VJKCT"
   },
   "outputs": [],
   "source": [
    "prompt = traduza(\"\"\"\n",
    "Proporcione un resumen muy breve en cuatro bullets para el siguiente artículo:\n",
    "\n",
    "Nuestras computadoras cuánticas funcionan manipulando qubits de una manera orquestada que llamamos algoritmos cuánticos.\n",
    "El desafío es que los qubits son tan sensibles que incluso la luz dispersa puede causar errores de cálculo, y el problema empeora a medida que crecen las computadoras cuánticas.\n",
    "Esto tiene consecuencias significativas, ya que los mejores algoritmos cuánticos que conocemos para ejecutar aplicaciones útiles requieren que las tasas de error de nuestros qubits sean mucho más bajas que las que tenemos hoy.\n",
    "Para llenar este vacío, necesitaremos la corrección del error cuántico.\n",
    "La corrección de errores cuánticos protege la información al codificarla en múltiples qubits físicos para formar un \"qubit lógico\" y se cree que es la única forma de producir una computadora cuántica a gran escala con tasas de error lo suficientemente bajas como para realizar cálculos útiles.\n",
    "En lugar de calcular en los qubits individuales, calcularemos en qubits lógicos. Al codificar un mayor número de qubits físicos en nuestro procesador cuántico en un qubit lógico, esperamos reducir las tasas de error para permitir algoritmos cuánticos útiles.\n",
    "\n",
    "Bullets:\n",
    "\n",
    "\"\"\", \"en\")\n",
    "\n",
    "print(\n",
    "    traduza(generation_model.predict(prompt, temperature=0.2, max_output_tokens=256, top_k=1, top_p=0.8).text, \"es\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yE7y-clBJKCT"
   },
   "source": [
    "### Sumarizar diálogos com tarefas realizadas\n",
    "O sumário do diálogo envolve condensar uma conversa em um formato mais curto para que você não precise ler toda a discussão, mas possa aproveitar um resumo. Neste exemplo, você pede ao modelo para resumir uma conversa de exemplo entre um cliente de varejo online e um agente de suporte e incluir tarefas no final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SV-BWzRhJKCT"
   },
   "outputs": [],
   "source": [
    "prompt = traduza(\"\"\"\n",
    "Genere un resumen de la siguiente conversación y, al final, resuma las tareas para el agente de soporte:\n",
    "\n",
    "Cliente: Hola, soy Joe y recibí el artículo equivocado.\n",
    "\n",
    "Agente de soporte: Hola José. ¿Cómo le gustaría ver esto resuelto?\n",
    "\n",
    "Cliente: Quiero devolver el artículo y obtener un reembolso, por favor.\n",
    "\n",
    "Agente de apoyo: Por supuesto. Puedo procesar el reembolso por usted ahora. ¿Puedo tener su número de orden por favor?\n",
    "\n",
    "Cliente: Es [NÚMERO DE PEDIDO].\n",
    "\n",
    "Agente de soporte: Gracias. He procesado el reembolso y te devolveremos el dinero en un plazo de 14 días.\n",
    "\n",
    "Cliente: Muchas gracias.\n",
    "\n",
    "Agente de apoyo: De nada, José. ¡Tenga un buen día!\n",
    "\n",
    "Resumen:\n",
    "\"\"\", \"en\")\n",
    "\n",
    "print(\n",
    "    traduza(generation_model.predict(prompt, temperature=0.2, max_output_tokens=256, top_k=40, top_p=0.8).text, \"es\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LlOgWzmNJKCT"
   },
   "source": [
    "### Tokenização de hashtag\n",
    "A tokenização de hashtag é o processo de pegar um pedaço de texto e obter os \"tokens\" de hashtag. Você pode usar isso, por exemplo, se quiser gerar hashtags para suas campanhas de mídia social. Neste exemplo, você pega [este tweet do Google Cloud](https://twitter.com/googlecloud/status/1649127992348606469) e gera algumas hashtags que pode usar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BWa8rNV0JKCT"
   },
   "outputs": [],
   "source": [
    "prompt = traduza(\"\"\"\n",
    "Tokenizar los hashtags de este tuit:\n",
    "\n",
    "Nube de Google\n",
    "@googlecloud\n",
    "¿Cómo pueden los datos ayudar a nuestro planeta cambiante? 🌎\n",
    "\n",
    "En honor al #DíaDeLaTierra este fin de semana, nos enorgullece compartir cómo nos asociamos con\n",
    "@ClimateEngine para aprovechar el poder de los datos geoespaciales e impulsar hacia un futuro más sostenible.\n",
    "\n",
    "Mira cómo → https://goo.gle/3mOUfts\n",
    "\"\"\", \"en\")\n",
    "\n",
    "print(\n",
    "    generation_model.predict(prompt, temperature=0.8, max_output_tokens=1024, top_k=40, top_p=0.8).text\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7f-w7mUxJKCT"
   },
   "source": [
    "### Geração de títulos e cabeçalhos\n",
    "Abaixo, você pede ao modelo para gerar cinco opções para possíveis combinações de título/cabeçalho para um determinado trecho de texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MWNri4DTJKCU"
   },
   "outputs": [],
   "source": [
    "prompt = traduza(\"\"\"\n",
    "Escribe un título para este texto, dame cinco opciones:\n",
    "Ya sea para ayudar a los médicos a identificar enfermedades o encontrar fotos de \"abrazos\", la IA está detrás de gran parte del trabajo que hacemos en Google. Y en nuestro Laboratorio de Arte y Cultura en París, hemos estado experimentando cómo se puede usar la IA para beneficiar la cultura.\n",
    "Hoy compartimos nuestros últimos experimentos: prototipos que se basan en siete años de trabajo en asociación con 1500 instituciones culturales de todo el mundo.\n",
    "Cada una de estas aplicaciones experimentales ejecuta algoritmos de inteligencia artificial en segundo plano para permitirle descubrir conexiones culturales ocultas en archivos e incluso encontrar obras de arte que coincidan con la decoración de su hogar\".\n",
    "\"\"\", \"en\")\n",
    "\n",
    "print(\n",
    "    traduza(generation_model.predict(prompt, temperature=0.8, max_output_tokens=256, top_k=1, top_p=0.8).text, \"es\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zcpmZnwKJKCU"
   },
   "source": [
    "## Avaliação\n",
    "Você pode avaliar os resultados das tarefas de resumo usando [ROUGE](https://en.wikipedia.org/wiki/ROUGE_(metric)) como uma estrutura de avaliação. `ROUGE` (Recall-Oriented Understudy for Gisting Evaluation) são medidas para determinar automaticamente a qualidade de um resumo comparando-o com outros resumos (ideais) criados por humanos. As medidas contam o número de unidades sobrepostas, como n-gram, sequências de palavras e pares de palavras entre o resumo gerado por computador a ser avaliado e os resumos ideais criados por humanos.\n",
    "\n",
    "\n",
    "O primeiro passo é instalar a biblioteca `ROUGE`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tJcl38ElJKCU"
   },
   "outputs": [],
   "source": [
    "!pip install rouge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iD9eKq3SJKCU"
   },
   "source": [
    "Crie um resumo a partir de um LLM que você pode usar para comparar com um resumo gerado por humanos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "37m_fb-HJKCU"
   },
   "outputs": [],
   "source": [
    "from rouge import Rouge\n",
    "\n",
    "ROUGE = Rouge()\n",
    "\n",
    "prompt = traduza(\"\"\"\n",
    "Proporcione un resumen muy breve, de cuatro oraciones como máximo, para el siguiente artículo:\n",
    "\n",
    "Nuestras computadoras cuánticas funcionan manipulando qubits de una manera orquestada que llamamos algoritmos cuánticos.\n",
    "El desafío es que los qubits son tan sensibles que incluso la luz dispersa puede causar errores de cálculo, y el problema empeora a medida que crecen las computadoras cuánticas.\n",
    "Esto tiene consecuencias significativas, ya que los mejores algoritmos cuánticos que conocemos para ejecutar aplicaciones útiles requieren que las tasas de error de nuestros qubits sean mucho más bajas que las que tenemos hoy.\n",
    "Para llenar este vacío, necesitaremos la corrección del error cuántico.\n",
    "La corrección de errores cuánticos protege la información al codificarla en múltiples qubits físicos para formar un \"qubit lógico\" y se cree que es la única forma de producir una computadora cuántica a gran escala con tasas de error lo suficientemente bajas como para realizar cálculos útiles.\n",
    "En lugar de calcular en los qubits individuales, calcularemos en qubits lógicos. Al codificar un mayor número de qubits físicos en nuestro procesador cuántico en un qubit lógico, esperamos reducir las tasas de error para permitir algoritmos cuánticos útiles.\n",
    "\n",
    "Resumen:\n",
    "\n",
    "\"\"\", \"en\")\n",
    "\n",
    "candidate = traduza(generation_model.predict(prompt, temperature=0.1, max_output_tokens=1024, top_k=40, top_p=0.9).text, \"es\")\n",
    "\n",
    "print(candidate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b44f9872e1ba"
   },
   "source": [
    "You will also need a human-generated summary that we will use to compare to the `candidate` generated by the model. We will call this `reference`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D0qNdPzOJKCc"
   },
   "outputs": [],
   "source": [
    "reference = \"Las computadoras cuánticas son sensibles al ruido y los errores. Para llenar este vacío, necesitaremos la corrección de errores cuánticos. La corrección de errores cuánticos protege la información mediante la codificación de múltiples qubits físicos para formar un 'qubit lógico'.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1KKaYhzwJKCc"
   },
   "source": [
    "Agora você pode pegar o candidato e a referência para avaliar o desempenho. Neste caso, ROUGE lhe dará:\n",
    "\n",
    "- `rouge-1`, que mede a sobreposição de unigramas\n",
    "- `rouge-2`, que mede a sobreposição de bigramas\n",
    "- `rouge-l`, que mede a maior subsequência comum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FHUH6VuTJKCc"
   },
   "outputs": [],
   "source": [
    "ROUGE.get_scores(candidate, reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "text_summarization.ipynb",
   "toc_visible": true
  },
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m107",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m107"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "local-python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
